{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Library Imports"
      ],
      "metadata": {
        "id": "nkKo_NgVByw-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeBSz8JP7RnE",
        "outputId": "c8cdc556-b3d2-40af-921d-d5bfd3c5f4b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mglearn in /usr/local/lib/python3.9/dist-packages (0.1.9)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from mglearn) (1.2.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.9/dist-packages (from mglearn) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mglearn) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from mglearn) (8.4.0)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.9/dist-packages (from mglearn) (0.11.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from mglearn) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from mglearn) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mglearn) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mglearn) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mglearn) (4.39.3)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mglearn) (5.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mglearn) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mglearn) (1.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mglearn) (23.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mglearn) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->mglearn) (2022.7.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->mglearn) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->mglearn) (3.1.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->mglearn) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mglearn) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# General Libraries\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os               # para manipulacion de directorios\n",
        "import shutil           # para eliminar carpetas no vacias\n",
        "!pip install mglearn    # el comando 'import mglearn' no funcionaba\n",
        "\n",
        "# Preprocessing\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# CountVectorizer | TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# Cross Validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# GridSearch\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# LogisticRegression Classifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# SVM Classifier\n",
        "from sklearn import svm\n",
        "\n",
        "# KNN Clasificator\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
        "\n",
        "# Gaussian NaiveBayes Clasificator\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# RandomForest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# DecisionTree (Classifier and Regressor)\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Graphics library\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# MultiClass\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# MultiOutput\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import make_scorer, precision_recall_fscore_support\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read CSV\n",
        "**Selección del la personalidad**\n",
        "\n",
        "Se utiliza un valor dentro del rango de las personalidades para entrenar el clasificador binario en la personalidad seleccionada.\n",
        "Los cuales tienen un total de 225 filas y cuentan con la siguiente estructura en columnas:\n",
        "\n",
        "*   ID: Number\n",
        "*   Personality: ['si', 'no']\n",
        "*   Autodescripción: String"
      ],
      "metadata": {
        "id": "uRLTtG05Jft2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Dataset\n",
        "\n",
        "#path_colab  = 'https://drive.google.com/uc?id=1EXOwzmfqc0Wvlg7vQTu0Z6wG9pD15H2_'#\"./_All_Classes_number.csv\"\n",
        "#path_colab  = 'https://drive.google.com/uc?id=1lt7U63P-tSD7fPgshEFMjw651qCGihys'#\"./Augment_All_Classes_number.csv -> augment_gpt3_multilabel.csv # 227 texts\n",
        "#path_colab   = 'https://drive.google.com/uc?id=1YYQXZE7LWVzalpit3auAWCKBnrddGCbO'# augment_gpt3_multilabel_fix.csv #192 texts\n",
        "#path_colab  = 'https://drive.google.com/uc?id=1FFyWdFr-qpY2AsjRG8XoMo-JkcyxmsLg'#\"./augment_gpt4_multilabel_RespPerc.csv\" # 327 texts\n",
        "path_colab  = 'https://drive.google.com/uc?id=1m8m8pIv3RN0zCvG3QdSOc1qxE-5SKGF6'#\"./augment_gpt4_multilabel_RespPerc_fix.csv\" # 297 texts\n",
        "\n",
        "\n",
        "# With ONLY URL\n",
        "if path_colab.startswith('http'):\n",
        "  print(\"Ubication WEB\")\n",
        "  #path_colab='https://drive.google.com/uc?id=' + path_colab.split('/')[-2]\n",
        "else: print(\"Ubication Local\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqV0cvkhCyEb",
        "outputId": "c07b6cfd-d6e9-4a9b-8f61-735b48aee354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ubication WEB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar un CSV con pandas a un formato DataFrame (df)\n",
        "\n",
        "df = pd.read_csv(\n",
        "    path_colab,\n",
        "    encoding = \"utf-8\",\n",
        "    header = 0\n",
        ")\n",
        "\n",
        "# Obtener TEXTOS\n",
        "texts_unprocessed = list(df[\"Autodescripción\"])\n",
        "\n",
        "# Obtener PERSONALIDADES\n",
        "df_all_classes = df.drop(['ID', 'Autodescripción'], axis=1)\n",
        "#print(df_all_classes)\n",
        "counts = []\n",
        "categories = list(df_all_classes.columns.values)\n",
        "for i in categories:\n",
        "    counts.append((i, df_all_classes[i].sum()))\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ohajXUXZJEsh",
        "outputId": "cdb34de4-c84c-41eb-d44e-d69174120ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    ID  AgradPerc  ApertPerc  ExtravPerc  NeurPerc  RespPerc  \\\n",
              "0   15          0          1           1         1         0   \n",
              "1   35          0          0           0         0         0   \n",
              "2   54          0          1           0         1         1   \n",
              "3  123          0          0           0         0         0   \n",
              "4  135          0          0           0         1         0   \n",
              "\n",
              "                                     Autodescripción  \n",
              "0  me considero con una personalidad fuerte; norm...  \n",
              "1  Soy una persona por lo generalmente muy alegre...  \n",
              "2  Soy una persona confiable; que se encuentra pa...  \n",
              "3  Yo creo que mi personalidad o mi forma de ser;...  \n",
              "4  Me concidero una chica amable pero no muy soci...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f56df0b9-a1fc-4e7e-ab0e-17b9a76a6905\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>AgradPerc</th>\n",
              "      <th>ApertPerc</th>\n",
              "      <th>ExtravPerc</th>\n",
              "      <th>NeurPerc</th>\n",
              "      <th>RespPerc</th>\n",
              "      <th>Autodescripción</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>me considero con una personalidad fuerte; norm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Soy una persona por lo generalmente muy alegre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Soy una persona confiable; que se encuentra pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>123</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yo creo que mi personalidad o mi forma de ser;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>135</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Me concidero una chica amable pero no muy soci...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f56df0b9-a1fc-4e7e-ab0e-17b9a76a6905')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f56df0b9-a1fc-4e7e-ab0e-17b9a76a6905 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f56df0b9-a1fc-4e7e-ab0e-17b9a76a6905');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# obtener el número total de filas\n",
        "num_filas = df.shape[0]\n",
        "print(f\"Total de textos: {num_filas}\")\n",
        "\n",
        "# obtener el numero total de positivos y negativos de cada clase\n",
        "pos_AgradPerc = df['AgradPerc'].sum()\n",
        "pos_ApertPerc = df['ApertPerc'].sum()\n",
        "pos_ExtravPerc = df['ExtravPerc'].sum()\n",
        "pos_NeurPerc = df['NeurPerc'].sum()\n",
        "pos_RespPerc = df['RespPerc'].sum()\n",
        "\n",
        "print(f'''\n",
        "AgradPerc:  +({pos_AgradPerc}) -({num_filas-pos_AgradPerc})\n",
        "ApertPerc:  +({pos_ApertPerc}) -({num_filas-pos_ApertPerc})\n",
        "ExtravPerc: +({pos_ExtravPerc}) -({num_filas-pos_ExtravPerc})\n",
        "NeurPerc:   +({pos_NeurPerc}) -({num_filas-pos_NeurPerc})\n",
        "RespPerc:   +({pos_RespPerc}) -({num_filas-pos_RespPerc})\n",
        "''')\n",
        "\n",
        "''' Before\n",
        "Total de textos: 227\n",
        "AgradPerc:  +(173) -(54)\n",
        "ApertPerc:  +(144) -(83)\n",
        "ExtravPerc: +(60) -(167)\n",
        "NeurPerc:   +(102) -(125)\n",
        "RespPerc:   +(124) -(103) '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "sX2U6ojk53oF",
        "outputId": "a75008a4-eb9c-4649-b401-7c7cab940e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de textos: 297\n",
            "      \n",
            "AgradPerc:  +(143) -(154) \n",
            "ApertPerc:  +(144) -(153) \n",
            "ExtravPerc: +(70) -(227) \n",
            "NeurPerc:   +(152) -(145) \n",
            "RespPerc:   +(114) -(183) \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Before\\nTotal de textos: 227\\nAgradPerc:  +(173) -(54) \\nApertPerc:  +(144) -(83) \\nExtravPerc: +(60) -(167) \\nNeurPerc:   +(102) -(125) \\nRespPerc:   +(124) -(103) '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocesamiento\n",
        "**Preprocesamiento del texto (opcional)**\n",
        "\n",
        "Es posible realizar una limpieza del texto, quitando carácteres innecesarios como números, símbolos, e incluso palabras que no aportan significancia a la oración.\n",
        "\n",
        "Antes de aplicar la funcion CountVectorizer o TfidfVectorizer (es decir, obtener la representación), es posible realizar un preprocesamiento del texto de entrada para ´limpiarlo´ un poco.\n",
        "\n",
        "En este caso, luego de leer el corpus se procede a preprocesar el texto de la columna Autodescripción con las siguientes técnicas."
      ],
      "metadata": {
        "id": "clNA1nToKxwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(texto):\n",
        "    texto = re.sub(r'[^\\w ]', \"\", texto)      # Eliminar todo lo que no sea una palabra\n",
        "    texto = texto.lower()                     # Pasa el texto a minúscula\n",
        "    letras_dobles = \"abdfghijkmnñpqstuvwxyz\"  # Remover letras con 2 ocurrencias (con excepciones). Excepciones: ee-cc-ll-rr-oo (y mayus)\n",
        "    letras_dobles += letras_dobles.upper()\n",
        "    texto = re.sub(\"(?P<char>[\" + re.escape(letras_dobles) + \"])(?P=char)+\", r\"\\1\", texto)\n",
        "    texto = re.sub(r'([\\w\\W])\\1{2,}', r'\\1', texto)  # remover caracteres que se repiten al menos 3 veces\n",
        "    return texto\n",
        "\n",
        "texts_processed = []\n",
        "\n",
        "for i in texts_unprocessed:\n",
        "    x = preprocessing(i)\n",
        "    texts_processed.append(x)\n",
        "\n",
        "print(\"Muestra procesada(size=%d): %s\"       %( len(texts_processed[0]), texts_processed[0]) )\n",
        "print(\"\\nMuestra sin procesar(size=%d): %s\"  %( len(texts_unprocessed[0]), texts_unprocessed[0]) )\n",
        "\n",
        "\n",
        "# Selección de Texto original o preprocesado (Comentar el que no se utiliza)\n",
        "\n",
        "# texts = texts_unprocessed\n",
        "texts = texts_processed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPoT8LtbKzN0",
        "outputId": "db0945c0-98e0-417b-88ed-84952b283aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Muestra procesada(size=3838): me considero con una personalidad fuerte normalmente me muestro bastante mala con la gente que no conozco pero con mis amigos soy alguien distinto soy medio distante no soy de ser muy cariñosa siempre depende la otra persona siempre me considere muy divertida me encanta hacer reír a los demás soy muy deportista me gusta estar en movimiento desde los 4 años que hago deporte hice danza y también salgo a trotar o andar en rollers mis metas en la vida son recibirme viajar y tener 2 hijos hoy en día me siento bien años anteriores no la estaba pasando muy bien pero empece a ver el lado lindo de la vida gracias a mis amigos y mi familia aunque soy muy desapegada la familia y amigos son algo muy importante en mi vida actualmente vivo con mi tía que es como mi mamá ella es la persona más importante y después está papá gracias a ella estoy donde estoy y estudiando lo que me gusta siento que el por qué me gusta la psicología forma parte de mi personalidad siempre me gustó ayudar a los demás en lo que pueda me gusta tener la razón siempre jaja así que soy de estar discutiendo y peleando todo el tiempo siempre intento convencer a los demás de que si tengo razón siento que esto es algo malo y algo bueno malo porque me lleva a tener peleas y soy bastante terca pero el lado bueno es que siento que si tengo una meta hago lo posible por llevarla a caboesta última semana fue complicada ya que tuve que pasar mucho tiempo en familia y no estoy muy acostumbrada y las veces que convivimos peleamos constantemente vivo con mi tía y hasta hace dos días mi prima su novio y su hija matilda el amor de mi vida jaja y eso lo complicaba un poco más ya que mi prima está acostumbrada a dormir hasta tarde y todas esas cosas  y con mi tía estamos acostumbradas a levantarnos temprano limpiar comprar la comida temprano también y eso lleva a más peleas jaja ahora esta todo mejor mi prima se mudo a un departamento que está atrás de mi casa un poco triste porque extraño a matilda pero nos vemos todos los días igual lo malo de toda la semana es no poder salir a ningún lado aunque en mi vida normal no salgo tanto esta última semana conocí a una persona que se ganó mi corazón y algo malo de la cuarentena también es no poder ir a visitarlo también visitar a mis amigos de la secundaria ya que todos estudian en córdoba le enseñé a mi prima a jugar al truco jugamos todas las noches al chinchon la mayoría de las veces peleamos jaja todos en mi familia tenemos esa personalidad fuerte y querer tener la razón por eso es que peleamos tanto pero en realidad nos amamos y bueno ya no se que más decirbueno en 5 años me veo con mi propio lugar de trabajo acá en merlo porque siempre digo que cuando me reciba voy a volver a donde vivo porque siempre me gustó y gusta mi pueblo en pareja aunque eso no me importa en realidad jaja y con mi personalidad es difícil que me dure una relación jajaja también me veo haciendo pequeños viajes que no pude hacer durante mi carrera ya que para mi es complicado porque estoy todo el tiempo estudiando y en verano trabajo me veo haciendo deporte siempre quise seguir jugando al voley o al handball así que seguramente me veo jugando a alguno de esos dos deportes también y esta es importante me veo viviendo sola ya que gracias a mamá que me dejo una casa hermosa voy a tener donde vivir cuando me reciba me veo sintiéndome bien realizada relajada también me veo capaz que me veo con por lo menos un hijo aunque me parece un poco adelantado pero si ya estoy recibida supongo que no va haber problema con mi familia me veo bien mis sobrinos ya van a estar grandes anhelo mucho verlos crecer que vayan a la escuela espero que me visiten mucho ya que seguro voy a ser la tía copada y la que les va a comprar todo y malcriarlos como mi tía hizo conmigo espero que para ese entonces mi hermano vuelva a vivir a merlo\n",
            "\n",
            "Muestra sin procesar(size=3934): me considero con una personalidad fuerte; normalmente me muestro bastante \"mala\" con la gente que no conozco; pero con mis amigos soy alguien distinto. soy medio distante; no soy de ser muy cariñosa; siempre depende la otra persona. siempre me considere muy divertida; me encanta hacer reír a los demás. soy muy deportista; me gusta estar en movimiento; desde los 4 años que hago deporte; hice danza y también salgo a trotar o andar en rollers. mis metas en la vida son recibirme; viajar y tener 2 hijos. hoy en día me siento bien; años anteriores no la estaba pasando muy bien; pero empece a ver el lado lindo de la vida; gracias a mis amigos y mi familia. aunque soy muy desapegada; la familia y amigos son algo muy importante en mi vida; actualmente vivo con mi tía (que es como mi mamá); ella es la persona más importante y después está papá; gracias a ella estoy donde estoy y estudiando lo que me gusta. siento que el por qué me gusta la psicología forma parte de mi personalidad; siempre me gustó ayudar a los demás; en lo que pueda. me gusta tener la razón siempre jaja; así que soy de estar discutiendo y peleando todo el tiempo; siempre intento convencer a los demás de que si tengo razón. siento que esto es algo malo y algo bueno; malo porque me lleva a tener peleas y soy bastante terca; pero el lado bueno es que siento que si tengo una meta hago lo posible por llevarla a cabo..esta última semana fue complicada ya que tuve que pasar mucho tiempo en familia y no estoy muy acostumbrada; y las veces que convivimos peleamos constantemente. vivo con mi tía y hasta hace dos días mi prima; su novio y su hija (matilda; el amor de mi vida jaja) y eso lo complicaba un poco más; ya que mi prima está acostumbrada a dormir hasta tarde y todas esas cosas ; y con mi tía estamos acostumbradas a levantarnos temprano; limpiar; comprar la comida temprano también y eso lleva a más peleas jaja. ahora esta todo mejor; mi prima se mudo a un departamento que está atrás de mi casa (un poco triste; porque extraño a matilda) pero nos vemos todos los días igual. lo malo de toda la semana es no poder salir a ningún lado; aunque en mi vida normal no salgo tanto. esta última semana conocí a una persona que se ganó mi corazón y algo malo de la cuarentena también es no poder ir a visitarlo. también visitar a mis amigos de la secundaria (ya que todos estudian en córdoba). le enseñé a mi prima a jugar al truco; jugamos todas las noches al chinchon (la mayoría de las veces peleamos jaja); todos en mi familia tenemos esa personalidad fuerte y querer tener la razón; por eso es que peleamos tanto; pero en realidad nos amamos y bueno; ya no se que más decir.bueno; en 5 años me veo con mi propio lugar de trabajo acá en merlo; porque siempre digo que cuando me reciba voy a volver a donde vivo porque siempre me gustó y gusta mi pueblo; en pareja (aunque eso no me importa en realidad jaja) y con mi personalidad es difícil que me dure una relación jajaja; también me veo haciendo pequeños viajes que no pude hacer durante mi carrera; ya que para mi es complicado porque estoy todo el tiempo estudiando y en verano trabajo. me veo haciendo deporte; siempre quise seguir jugando al voley o al handball; así que seguramente me veo jugando a alguno de esos dos deportes. también; y esta es importante; me veo viviendo sola; ya que gracias a mamá que me dejo una casa hermosa; voy a tener donde vivir cuando me reciba. me veo sintiéndome bien; realizada; relajada también me veo. CAPAZ que me veo con por lo menos un hijo; aunque me parece un poco adelantado; pero si ya estoy recibida; supongo que no va haber problema. con mi familia me veo bien; mis sobrinos ya van a estar grandes; anhelo mucho verlos crecer; que vayan a la escuela; espero que me visiten mucho ya que seguro voy a ser la tía copada y la que les va a comprar todo y malcriarlos; como mi tía hizo conmigo. espero que para ese entonces mi hermano vuelva a vivir a merlo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizar stop_words extendido\n",
        "\n",
        "# stopwords_sp_web = [\"algún\",\"alguna\",\"algunas\",\"alguno\",\"algunos\",\"ambos\",\"ampleamos\",\"ante\",\"antes\",\"aquel\",\"aquellas\",\"aquellos\",\"aqui\",\"arriba\",\"atras\",\"bajo\",\"bastante\",\"bien\",\"cada\",\"cierta\",\"ciertas\",\"cierto\",\"ciertos\",\"como\",\"con\",\"conseguimos\",\"conseguir\",\"consigo\",\"consigue\",\"consiguen\",\"consigues\",\"cual\",\"cuando\",\"dentro\",\"desde\",\"donde\",\"dos\",\"el\",\"ellas\",\"ellos\",\"empleais\",\"emplean\",\"emplear\",\"empleas\",\"empleo\",\"en\",\"encima\",\"entonces\",\"entre\",\"era\",\"eramos\",\"eran\",\"eras\",\"eres\",\"es\",\"esta\",\"estaba\",\"estado\",\"estais\",\"estamos\",\"estan\",\"estoy\",\"fin\",\"fue\",\"fueron\",\"fui\",\"fuimos\",\"gueno\",\"ha\",\"hace\",\"haceis\",\"hacemos\",\"hacen\",\"hacer\",\"haces\",\"hago\",\"incluso\",\"intenta\",\"intentais\",\"intentamos\",\"intentan\",\"intentar\",\"intentas\",\"intento\",\"ir\",\"la\",\"largo\",\"las\",\"lo\",\"los\",\"mientras\",\"mio\",\"modo\",\"muchos\",\"muy\",\"nos\",\"nosotros\",\"otro\",\"para\",\"pero\",\"podeis\",\"podemos\",\"poder\",\"podria\",\"podriais\",\"podriamos\",\"podrian\",\"podrias\",\"por\",\"por qué\",\"porque\",\"primero\",\"puede\",\"pueden\",\"puedo\",\"quien\",\"sabe\",\"sabeis\",\"sabemos\",\"saben\",\"saber\",\"sabes\",\"ser\",\"si\",\"siendo\",\"sin\",\"sobre\",\"sois\",\"solamente\",\"solo\",\"somos\",\"soy\",\"su\",\"sus\",\"también\",\"teneis\",\"tenemos\",\"tener\",\"tengo\",\"tiempo\",\"tiene\",\"tienen\",\"todo\",\"trabaja\",\"trabajais\",\"trabajamos\",\"trabajan\",\"trabajar\",\"trabajas\",\"trabajo\",\"tras\",\"tuyo\",\"ultimo\",\"un\",\"una\",\"unas\",\"uno\",\"unos\",\"usa\",\"usais\",\"usamos\",\"usan\",\"usar\",\"usas\",\"uso\",\"va\",\"vais\",\"valor\",\"vamos\",\"van\",\"vaya\",\"verdad\",\"verdadera\",\"verdadero\",\"vosotras\",\"vosotros\",\"voy\",\"yo\",\"él\",\"ésta\",\"éstas\",\"éste\",\"éstos\",\"última\",\"últimas\",\"último\",\"últimos\",\"a\",\"añadió\",\"aún\",\"actualmente\",\"adelante\",\"además\",\"afirmó\",\"agregó\",\"ahí\",\"ahora\",\"al\",\"algo\",\"alrededor\",\"anterior\",\"apenas\",\"aproximadamente\",\"aquí\",\"así\",\"aseguró\",\"aunque\",\"ayer\",\"buen\",\"buena\",\"buenas\",\"bueno\",\"buenos\",\"cómo\",\"casi\",\"cerca\",\"cinco\",\"comentó\",\"conocer\",\"consideró\",\"considera\",\"contra\",\"cosas\",\"creo\",\"cuales\",\"cualquier\",\"cuanto\",\"cuatro\",\"cuenta\",\"da\",\"dado\",\"dan\",\"dar\",\"de\",\"debe\",\"deben\",\"debido\",\"decir\",\"dejó\",\"del\",\"demás\",\"después\",\"dice\",\"dicen\",\"dicho\",\"dieron\",\"diferente\",\"diferentes\",\"dijeron\",\"dijo\",\"dio\",\"durante\",\"e\",\"ejemplo\",\"ella\",\"ello\",\"embargo\",\"encuentra\",\"esa\",\"esas\",\"ese\",\"eso\",\"esos\",\"está\",\"están\",\"estaban\",\"estar\",\"estará\",\"estas\",\"este\",\"esto\",\"estos\",\"estuvo\",\"ex\",\"existe\",\"existen\",\"explicó\",\"expresó\",\"fuera\",\"gran\",\"grandes\",\"había\",\"habían\",\"haber\",\"habrá\",\"hacerlo\",\"hacia\",\"haciendo\",\"han\",\"hasta\",\"hay\",\"haya\",\"he\",\"hecho\",\"hemos\",\"hicieron\",\"hizo\",\"hoy\",\"hubo\",\"igual\",\"indicó\",\"informó\",\"junto\",\"lado\",\"le\",\"les\",\"llegó\",\"lleva\",\"llevar\",\"luego\",\"lugar\",\"más\",\"manera\",\"manifestó\",\"mayor\",\"me\",\"mediante\",\"mejor\",\"mencionó\",\"menos\",\"mi\",\"misma\",\"mismas\",\"mismo\",\"mismos\",\"momento\",\"mucha\",\"muchas\",\"mucho\",\"nada\",\"nadie\",\"ni\",\"ningún\",\"ninguna\",\"ningunas\",\"ninguno\",\"ningunos\",\"no\",\"nosotras\",\"nuestra\",\"nuestras\",\"nuestro\",\"nuestros\",\"nueva\",\"nuevas\",\"nuevo\",\"nuevos\",\"nunca\",\"o\",\"ocho\",\"otra\",\"otras\",\"otros\",\"parece\",\"parte\",\"partir\",\"pasada\",\"pasado\",\"pesar\",\"poca\",\"pocas\",\"poco\",\"pocos\",\"podrá\",\"podrán\",\"podría\",\"podrían\",\"poner\",\"posible\",\"próximo\",\"próximos\",\"primer\",\"primera\",\"primeros\",\"principalmente\",\"propia\",\"propias\",\"propio\",\"propios\",\"pudo\",\"pueda\",\"pues\",\"qué\",\"que\",\"quedó\",\"queremos\",\"quién\",\"quienes\",\"quiere\",\"realizó\",\"realizado\",\"realizar\",\"respecto\",\"sí\",\"sólo\",\"se\",\"señaló\",\"sea\",\"sean\",\"según\",\"segunda\",\"segundo\",\"seis\",\"será\",\"serán\",\"sería\",\"sido\",\"siempre\",\"siete\",\"sigue\",\"siguiente\",\"sino\",\"sola\",\"solas\",\"solos\",\"son\",\"tal\",\"tampoco\",\"tan\",\"tanto\",\"tenía\",\"tendrá\",\"tendrán\",\"tenga\",\"tenido\",\"tercera\",\"toda\",\"todas\",\"todavía\",\"todos\",\"total\",\"trata\",\"través\",\"tres\",\"tuvo\",\"usted\",\"varias\",\"varios\",\"veces\",\"ver\",\"vez\",\"y\",\"ya\"]\n",
        "stopwords_sp_web_accent_less = set({\"algun\",\"alguna\",\"algunas\",\"alguno\",\"algunos\",\"ambos\",\"ampleamos\",\"ante\",\"antes\",\"aquel\",\"aquellas\",\"aquellos\",\"aqui\",\"arriba\",\"atras\",\"bajo\",\"bastante\",\"bien\",\"cada\",\"cierta\",\"ciertas\",\"cierto\",\"ciertos\",\"como\",\"con\",\"conseguimos\",\"conseguir\",\"consigo\",\"consigue\",\"consiguen\",\"consigues\",\"cual\",\"cuando\",\"dentro\",\"desde\",\"donde\",\"dos\",\"el\",\"ellas\",\"ellos\",\"empleais\",\"emplean\",\"emplear\",\"empleas\",\"empleo\",\"en\",\"encima\",\"entonces\",\"entre\",\"era\",\"eramos\",\"eran\",\"eras\",\"eres\",\"es\",\"esta\",\"estaba\",\"estado\",\"estais\",\"estamos\",\"estan\",\"estoy\",\"fin\",\"fue\",\"fueron\",\"fui\",\"fuimos\",\"gueno\",\"ha\",\"hace\",\"haceis\",\"hacemos\",\"hacen\",\"hacer\",\"haces\",\"hago\",\"incluso\",\"intenta\",\"intentais\",\"intentamos\",\"intentan\",\"intentar\",\"intentas\",\"intento\",\"ir\",\"la\",\"largo\",\"las\",\"lo\",\"los\",\"mientras\",\"mio\",\"modo\",\"muchos\",\"muy\",\"nos\",\"nosotros\",\"otro\",\"para\",\"pero\",\"podeis\",\"podemos\",\"poder\",\"podria\",\"podriais\",\"podriamos\",\"podrian\",\"podrias\",\"por\",\"por que\",\"porque\",\"primero\",\"puede\",\"pueden\",\"puedo\",\"quien\",\"sabe\",\"sabeis\",\"sabemos\",\"saben\",\"saber\",\"sabes\",\"ser\",\"si\",\"siendo\",\"sin\",\"sobre\",\"sois\",\"solamente\",\"solo\",\"somos\",\"soy\",\"su\",\"sus\",\"tambien\",\"teneis\",\"tenemos\",\"tener\",\"tengo\",\"tiempo\",\"tiene\",\"tienen\",\"todo\",\"trabaja\",\"trabajais\",\"trabajamos\",\"trabajan\",\"trabajar\",\"trabajas\",\"trabajo\",\"tras\",\"tuyo\",\"ultimo\",\"un\",\"una\",\"unas\",\"uno\",\"unos\",\"usa\",\"usais\",\"usamos\",\"usan\",\"usar\",\"usas\",\"uso\",\"va\",\"vais\",\"valor\",\"vamos\",\"van\",\"vaya\",\"verdad\",\"verdadera\",\"verdadero\",\"vosotras\",\"vosotros\",\"voy\",\"yo\",\"el\",\"esta\",\"estas\",\"este\",\"estos\",\"ultima\",\"ultimas\",\"ultimo\",\"ultimos\",\"a\",\"anadio\",\"aun\",\"actualmente\",\"adelante\",\"ademas\",\"afirmo\",\"agrego\",\"ahi\",\"ahora\",\"al\",\"algo\",\"alrededor\",\"anterior\",\"apenas\",\"aproximadamente\",\"aqui\",\"asi\",\"aseguro\",\"aunque\",\"ayer\",\"buen\",\"buena\",\"buenas\",\"bueno\",\"buenos\",\"como\",\"casi\",\"cerca\",\"cinco\",\"comento\",\"conocer\",\"considero\",\"considera\",\"contra\",\"cosas\",\"creo\",\"cuales\",\"cualquier\",\"cuanto\",\"cuatro\",\"cuenta\",\"da\",\"dado\",\"dan\",\"dar\",\"de\",\"debe\",\"deben\",\"debido\",\"decir\",\"dejo\",\"del\",\"demas\",\"despues\",\"dice\",\"dicen\",\"dicho\",\"dieron\",\"diferente\",\"diferentes\",\"dijeron\",\"dijo\",\"dio\",\"durante\",\"e\",\"ejemplo\",\"ella\",\"ello\",\"embargo\",\"encuentra\",\"esa\",\"esas\",\"ese\",\"eso\",\"esos\",\"esta\",\"estan\",\"estaban\",\"estar\",\"estara\",\"estas\",\"este\",\"esto\",\"estos\",\"estuvo\",\"ex\",\"existe\",\"existen\",\"explico\",\"expreso\",\"fuera\",\"gran\",\"grandes\",\"habia\",\"habian\",\"haber\",\"habra\",\"hacerlo\",\"hacia\",\"haciendo\",\"han\",\"hasta\",\"hay\",\"haya\",\"he\",\"hecho\",\"hemos\",\"hicieron\",\"hizo\",\"hoy\",\"hubo\",\"igual\",\"indico\",\"informo\",\"junto\",\"lado\",\"le\",\"les\",\"llego\",\"lleva\",\"llevar\",\"luego\",\"lugar\",\"mas\",\"manera\",\"manifesto\",\"mayor\",\"me\",\"mediante\",\"mejor\",\"menciono\",\"menos\",\"mi\",\"misma\",\"mismas\",\"mismo\",\"mismos\",\"momento\",\"mucha\",\"muchas\",\"mucho\",\"nada\",\"nadie\",\"ni\",\"ningun\",\"ninguna\",\"ningunas\",\"ninguno\",\"ningunos\",\"no\",\"nosotras\",\"nuestra\",\"nuestras\",\"nuestro\",\"nuestros\",\"nueva\",\"nuevas\",\"nuevo\",\"nuevos\",\"nunca\",\"o\",\"ocho\",\"otra\",\"otras\",\"otros\",\"parece\",\"parte\",\"partir\",\"pasada\",\"pasado\",\"pesar\",\"poca\",\"pocas\",\"poco\",\"pocos\",\"podra\",\"podran\",\"podria\",\"podrian\",\"poner\",\"posible\",\"proximo\",\"proximos\",\"primer\",\"primera\",\"primeros\",\"principalmente\",\"propia\",\"propias\",\"propio\",\"propios\",\"pudo\",\"pueda\",\"pues\",\"que\",\"que\",\"quedo\",\"queremos\",\"quien\",\"quienes\",\"quiere\",\"realizo\",\"realizado\",\"realizar\",\"respecto\",\"si\",\"solo\",\"se\",\"senalo\",\"sea\",\"sean\",\"segun\",\"segunda\",\"segundo\",\"seis\",\"sera\",\"seran\",\"seria\",\"sido\",\"siempre\",\"siete\",\"sigue\",\"siguiente\",\"sino\",\"sola\",\"solas\",\"solos\",\"son\",\"tal\",\"tampoco\",\"tan\",\"tanto\",\"tenia\",\"tendra\",\"tendran\",\"tenga\",\"tenido\",\"tercera\",\"toda\",\"todas\",\"todavia\",\"todos\",\"total\",\"trata\",\"traves\",\"tres\",\"tuvo\",\"usted\",\"varias\",\"varios\",\"veces\",\"ver\",\"vez\",\"y\",\"ya\"})\n",
        "stopwords_sp = list(stopwords_sp_web_accent_less)\n"
      ],
      "metadata": {
        "id": "cnMcSGcnTe2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vect_tf = TfidfVectorizer(\n",
        "    use_idf = False,            # default=True\n",
        "    lowercase = True,           # Lowercase: default=True\n",
        "    strip_accents = 'unicode',  # Remover acentos\n",
        "    stop_words = stopwords_sp,  # Palabras para no tener en cuenta ya que no agregan mucho significado a una oracion.\n",
        "    max_features = 500,         # maximo de vocabulario\n",
        "    max_df = 0.8,               # (frecuencia máxima de documentos) es un valor que representa el porcentaje máximo de documentos en los que un término puede aparecer para ser incluido en el vocabulario. Los términos que aparecen en más del max_df% de los documentos se consideran comunes y, por lo tanto, no son relevantes para el análisis.\n",
        "    min_df = 2,                 # (frecuencia mínima de documentos) es un valor entero que representa la frecuencia mínima con la que un término debe aparecer en los documentos para ser incluido en el vocabulario. Los términos que aparecen en menos de min_df documentos no se consideran relevantes para el análisis y se omiten del vocabulario.\n",
        "    analyzer = 'word',\n",
        "    norm=None\n",
        "    #ngram_range=(2,6)\n",
        ")\n",
        "\n",
        "vect_tfidf = TfidfVectorizer(\n",
        "    use_idf = True,             # default=True\n",
        "    lowercase = True,           # Lowercase: default=True\n",
        "    strip_accents = 'unicode',  # Remover acentos\n",
        "    stop_words = stopwords_sp,  # Palabras para no tener en cuenta ya que no agregan mucho significado a una oracion.\n",
        "    max_features = 500,         # maximo de vocabulario\n",
        "    max_df = 0.8,               # (frecuencia máxima de documentos) es un valor que representa el porcentaje máximo de documentos en los que un término puede aparecer para ser incluido en el vocabulario. Los términos que aparecen en más del max_df% de los documentos se consideran comunes y, por lo tanto, no son relevantes para el análisis.\n",
        "    min_df = 2,                 # (frecuencia mínima de documentos) es un valor entero que representa la frecuencia mínima con la que un término debe aparecer en los documentos para ser incluido en el vocabulario. Los términos que aparecen en menos de min_df documentos no se consideran relevantes para el análisis y se omiten del vocabulario.\n",
        "    analyzer = 'word',\n",
        "    norm=None\n",
        "    #ngram_range=(2,6)\n",
        ")\n",
        "\n",
        "vect_binary = CountVectorizer(\n",
        "    binary = True,              # default=True\n",
        "    lowercase = True,           # Lowercase: default=True\n",
        "    strip_accents = 'unicode',  # Remover acentos\n",
        "    stop_words = stopwords_sp,  # Palabras para no tener en cuenta ya que no agregan mucho significado a una oracion.\n",
        "    max_features = 500,         # maximo de vocabulario\n",
        "    max_df = 0.8,               # (frecuencia máxima de documentos) es un valor que representa el porcentaje máximo de documentos en los que un término puede aparecer para ser incluido en el vocabulario. Los términos que aparecen en más del max_df% de los documentos se consideran comunes y, por lo tanto, no son relevantes para el análisis.\n",
        "    min_df = 2,                 # (frecuencia mínima de documentos) es un valor entero que representa la frecuencia mínima con la que un término debe aparecer en los documentos para ser incluido en el vocabulario. Los términos que aparecen en menos de min_df documentos no se consideran relevantes para el análisis y se omiten del vocabulario.\n",
        "    analyzer = 'word',\n",
        "    #ngram_range=(2,6),\n",
        ")\n",
        "\n",
        "vect_count = CountVectorizer(\n",
        "    binary = False,             # default=True\n",
        "    lowercase = True,           # Lowercase: default=True\n",
        "    strip_accents = 'unicode',  # Remover acentos\n",
        "    stop_words = stopwords_sp,  # Palabras para no tener en cuenta ya que no agregan mucho significado a una oracion.\n",
        "    max_features = 500,         # maximo de vocabulario\n",
        "    max_df = 0.8,               # (frecuencia máxima de documentos) es un valor que representa el porcentaje máximo de documentos en los que un término puede aparecer para ser incluido en el vocabulario. Los términos que aparecen en más del max_df% de los documentos se consideran comunes y, por lo tanto, no son relevantes para el análisis.\n",
        "    min_df = 2,                 # (frecuencia mínima de documentos) es un valor entero que representa la frecuencia mínima con la que un término debe aparecer en los documentos para ser incluido en el vocabulario. Los términos que aparecen en menos de min_df documentos no se consideran relevantes para el análisis y se omiten del vocabulario.\n",
        "    analyzer = 'word',\n",
        "    #ngram_range=(2,6),\n",
        ")\n"
      ],
      "metadata": {
        "id": "kz2E0x8BWsng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the Representation\n",
        "\n",
        "# 1: TF           # (float) Frecuencia de términos mide la frecuencia con la que aparece un término en un documento.\n",
        "# 0: TFIDF        # (float) TF por la IDF (Aumenta el peso de los terminos menos frecuentes y disminuye el peso de los terminos mas frecuentes)\n",
        "# 2: BINARY       # (int) Coloca 1 o 0 si la palabra está contenida en el documento.\n",
        "# 3: COUNT        # (int) Coloca el total de palabras que aparecen en un documento.\n",
        "\n",
        "representations = [ vect_tf, vect_tfidf, vect_binary, vect_count ]\n",
        "represent_names = [ 'TF', 'TFIDF', 'BINARY', 'COUNT' ]\n",
        "\n",
        "REP = 2\n",
        "\n",
        "vect    = representations[REP]\n",
        "X_train = vect.fit_transform(texts) # Return: sparse matrix of (n_samples, n_features) Tf-idf-weighted document-term matrix.\n",
        "\n",
        "y = df[categories] # Se puede realizar de la siguiente manera tambien: df[['AgradPerc', 'ApertPerc', 'ExtravPerc', 'NeurPerc', 'RespPerc']]\n"
      ],
      "metadata": {
        "id": "yqEdu8f2X4ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "0_9Es3U3aDId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####MultinomialNB"
      ],
      "metadata": {
        "id": "3RlX7gpI3If-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MultinomialNB\n",
        "\n",
        "NB_pipeline = Pipeline([\n",
        "                ('tfidf', vect ),\n",
        "                ('clf', MultiOutputClassifier(MultinomialNB( fit_prior=True, class_prior=None  ))),\n",
        "            ])\n",
        "\n",
        "\n",
        "#scores = cross_val_score(NB_pipeline, texts, y, cv=5, scoring='f1_weighted')\n",
        "scores = cross_val_score(NB_pipeline, texts, y, cv=KFold(n_splits=5,shuffle=True, random_state=1), scoring='f1_weighted' )\n",
        "\n",
        "#print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "print(\"CV Accuracy Scores:\\n\", scores)\n",
        "print(\"Mean CV Accuracy: \", round(scores.mean(), 4))\n",
        "print(\"Standard Deviation: \", scores.std() * 2)\n",
        "\n",
        "''' Without Augment\n",
        "CV Accuracy Scores:\n",
        " [0.4233871  0.45818976 0.63650633 0.57364571 0.70289601]\n",
        "Mean CV Accuracy:  0.5589\n",
        "Standard Deviation:  0.21067762180105937 '''\n",
        "\n",
        "''' With Augment v1\n",
        "CV Accuracy Scores:\n",
        " [0.46858712 0.27240562 0.39256462 0.91675471 0.62596478]\n",
        "Mean CV Accuracy:  0.5353\n",
        "Standard Deviation:  0.44512042808733066 '''\n",
        "\n",
        "''' With Augment v2\n",
        "CV Accuracy Scores:\n",
        " [0.54008722 0.30036707 0.34858622 0.45204026 0.53869275]\n",
        "Mean CV Accuracy:  0.436\n",
        "Standard Deviation:  0.19529401683978515\n",
        "\n",
        "augment_gpt3_multilabel\n",
        "Mean CV Accuracy:  0.6718\n",
        "\n",
        "augment_gpt3_fix\n",
        "Mean CV Accuracy:  0.6546\n",
        "\n",
        "augment_gpt4_multilabel_RespPerc.csv\n",
        "Mean CV Accuracy:  0.646\n",
        "\n",
        "augment_gpt4_multilabel_RespPerc_fix.csv\n",
        "Mean CV Accuracy:  0.6055\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "KIt8C6sXnHne",
        "outputId": "eb8561fd-4f13-410c-d18d-fe732b5ec48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV Accuracy Scores:\n",
            " [0.57811075 0.62108373 0.63770941 0.60973748 0.54935405]\n",
            "Mean CV Accuracy:  0.5992\n",
            "Standard Deviation:  0.06326000972681407\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' With Augment v2\\nCV Accuracy Scores:\\n [0.54008722 0.30036707 0.34858622 0.45204026 0.53869275]\\nMean CV Accuracy:  0.436\\nStandard Deviation:  0.19529401683978515 \\n\\naugment_gpt3_multilabel\\nMean CV Accuracy:  0.6718\\n\\naugment_gpt3_fix\\nMean CV Accuracy:  0.6546\\n\\naugment_gpt4_multilabel_RespPerc.csv\\nMean CV Accuracy:  0.646\\n\\naugment_gpt4_multilabel_RespPerc_fix.csv\\nMean CV Accuracy:  0.6055\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos validación cruzada y obtenemos las predicciones\n",
        "#predicciones = cross_val_predict(NB_pipeline, texts, y, cv=5)\n",
        "predicciones = cross_val_predict(NB_pipeline, texts, y, cv=KFold(n_splits=5,shuffle=True, random_state=1))\n",
        "\n",
        "# Calculamos el f1_weighted para cada columna de salida y el f1_weighted medio ponderado\n",
        "f1_scores = []\n",
        "for i, columna in enumerate(y.columns):\n",
        "    f1 = f1_score(y[columna], predicciones[:, i], average='weighted')\n",
        "    f1_scores.append(f1)\n",
        "    print(f\"f1_weighted para {columna}: {f1:.4f}\")\n",
        "\n",
        "f1_weighted_media = sum(f1_scores) / len(f1_scores)\n",
        "print(f\"f1_weighted medio: {f1_weighted_media:.4f}\")\n",
        "\n",
        "''' Without Augment\n",
        "f1_weighted para AgradPerc: 0.4763\n",
        "f1_weighted para ApertPerc: 0.5827\n",
        "f1_weighted para ExtravPerc: 0.6431\n",
        "f1_weighted para NeurPerc: 0.5907\n",
        "f1_weighted para RespPerc: 0.6906\n",
        "f1_weighted medio: 0.5967 '''\n",
        "\n",
        "''' With Augment v1\n",
        "f1_weighted para AgradPerc: 0.4306\n",
        "f1_weighted para ApertPerc: 0.5628\n",
        "f1_weighted para ExtravPerc: 0.5370\n",
        "f1_weighted para NeurPerc: 0.5576\n",
        "f1_weighted para RespPerc: 0.8354\n",
        "f1_weighted medio: 0.5847 '''\n",
        "\n",
        "''' With Augment v2\n",
        "f1_weighted para AgradPerc: 0.3240\n",
        "f1_weighted para ApertPerc: 0.5319\n",
        "f1_weighted para ExtravPerc: 0.6943\n",
        "f1_weighted para NeurPerc: 0.6133\n",
        "f1_weighted para RespPerc: 0.5859\n",
        "f1_weighted medio: 0.5499\n",
        "\n",
        "augment_gpt3_multilabel\n",
        "f1_weighted para AgradPerc: 0.6378\n",
        "f1_weighted para ApertPerc: 0.5803\n",
        "f1_weighted para ExtravPerc: 0.6668\n",
        "f1_weighted para NeurPerc: 0.5639\n",
        "f1_weighted para RespPerc: 0.8585\n",
        "f1_weighted medio: 0.6615\n",
        "\n",
        "augment_gpt3_fix\n",
        "f1_weighted para AgradPerc: 0.6799\n",
        "f1_weighted para ApertPerc: 0.5257\n",
        "f1_weighted para ExtravPerc: 0.6183\n",
        "f1_weighted para NeurPerc: 0.5674\n",
        "f1_weighted para RespPerc: 0.8194\n",
        "f1_weighted medio: 0.6421\n",
        "\n",
        "augment_gpt4_multilabel_RespPerc.csv\n",
        "f1_weighted para AgradPerc: 0.6883\n",
        "f1_weighted para ApertPerc: 0.6487\n",
        "f1_weighted para ExtravPerc: 0.7114\n",
        "f1_weighted para NeurPerc: 0.6365\n",
        "f1_weighted para RespPerc: 0.7105\n",
        "f1_weighted medio: 0.6791\n",
        "\n",
        "augment_gpt4_multilabel_RespPerc_fix.csv\n",
        "f1_weighted para AgradPerc: 0.6557\n",
        "f1_weighted para ApertPerc: 0.6060\n",
        "f1_weighted para ExtravPerc: 0.7051\n",
        "f1_weighted para NeurPerc: 0.6492\n",
        "f1_weighted para RespPerc: 0.6810\n",
        "f1_weighted medio: 0.6594\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "SU0EivoWZTqo",
        "outputId": "f4fad221-2e77-4146-f4dc-3b2c52ee31c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_weighted para AgradPerc: 0.6687\n",
            "f1_weighted para ApertPerc: 0.6261\n",
            "f1_weighted para ExtravPerc: 0.6839\n",
            "f1_weighted para NeurPerc: 0.6252\n",
            "f1_weighted para RespPerc: 0.6712\n",
            "f1_weighted medio: 0.6550\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' With Augment v2\\nf1_weighted para AgradPerc: 0.3240\\nf1_weighted para ApertPerc: 0.5319\\nf1_weighted para ExtravPerc: 0.6943\\nf1_weighted para NeurPerc: 0.6133\\nf1_weighted para RespPerc: 0.5859\\nf1_weighted medio: 0.5499 \\n\\naugment_gpt3_multilabel\\nf1_weighted para AgradPerc: 0.6378\\nf1_weighted para ApertPerc: 0.5803\\nf1_weighted para ExtravPerc: 0.6668\\nf1_weighted para NeurPerc: 0.5639\\nf1_weighted para RespPerc: 0.8585\\nf1_weighted medio: 0.6615\\n\\naugment_gpt3_fix\\nf1_weighted para AgradPerc: 0.6799\\nf1_weighted para ApertPerc: 0.5257\\nf1_weighted para ExtravPerc: 0.6183\\nf1_weighted para NeurPerc: 0.5674\\nf1_weighted para RespPerc: 0.8194\\nf1_weighted medio: 0.6421\\n\\naugment_gpt4_multilabel_RespPerc.csv\\nf1_weighted para AgradPerc: 0.6883\\nf1_weighted para ApertPerc: 0.6487\\nf1_weighted para ExtravPerc: 0.7114\\nf1_weighted para NeurPerc: 0.6365\\nf1_weighted para RespPerc: 0.7105\\nf1_weighted medio: 0.6791\\n\\naugment_gpt4_multilabel_RespPerc_fix.csv\\nf1_weighted para AgradPerc: 0.6557\\nf1_weighted para ApertPerc: 0.6060\\nf1_weighted para ExtravPerc: 0.7051\\nf1_weighted para NeurPerc: 0.6492\\nf1_weighted para RespPerc: 0.6810\\nf1_weighted medio: 0.6594\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####SVC_pipeline"
      ],
      "metadata": {
        "id": "rlzXfnKW3NSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVC\n",
        "SVC_pipeline = Pipeline([\n",
        "                ('tfidf', vect ),\n",
        "                ('clf', MultiOutputClassifier(svm.SVC(random_state=1, class_weight='balanced'), n_jobs=1)),\n",
        "            ])\n",
        "\n",
        "#scores = cross_val_score(SVC_pipeline, texts, y, cv=5, scoring='f1_weighted')\n",
        "scores = cross_val_score(SVC_pipeline, texts, y, cv=KFold(n_splits=5,shuffle=True, random_state=1), scoring='f1_weighted' )\n",
        "\n",
        "#print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "print(\"CV Accuracy Scores:\\n\", scores)\n",
        "print(\"Mean CV Accuracy: \", round(scores.mean(), 4))\n",
        "print(\"Standard Deviation: \", scores.std() * 2)\n",
        "\n",
        "''' Without Augment\n",
        "CV Accuracy Scores:\n",
        " [0.48860867 0.4608431  0.60044444 0.52831558 0.6391725 ]\n",
        "Mean CV Accuracy:  0.5435\n",
        "Standard Deviation:  0.13407962374128868 '''\n",
        "\n",
        "''' With Augment v1\n",
        "CV Accuracy Scores:\n",
        " [0.55075414 0.35498309 0.49354399 0.92928386 0.64544569]\n",
        "Mean CV Accuracy:  0.5948\n",
        "Standard Deviation:  0.38382225243583024 '''\n",
        "\n",
        "''' With Augment v2\n",
        "CV Accuracy Scores:\n",
        " [0.48033538 0.22054698 0.4483185  0.58703983 0.67637448]\n",
        "Mean CV Accuracy:  0.4825\n",
        "Standard Deviation:  0.30764698041928257\n",
        "\n",
        "augment_gpt3_multilabel\n",
        "Mean CV Accuracy:  0.6999\n",
        "\n",
        "augment_gpt3_fix\n",
        "Mean CV Accuracy:  0.6388\n",
        "\n",
        "augment_gpt4_multilabel_RespPerc.csv\n",
        "Mean CV Accuracy:  0.6848\n",
        "\n",
        "augment_gpt4_multilabel_RespPerc_fix.csv\n",
        "Mean CV Accuracy:  0.6365\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEa1Wmhlv_BE",
        "outputId": "63be682e-d76b-4676-f546-025b313768bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV Accuracy Scores:\n",
            " [0.60088058 0.64908316 0.6659512  0.67064581 0.56967489]\n",
            "Mean CV Accuracy:  0.6312\n",
            "Standard Deviation:  0.07893298453956053\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' With Augment v2\\nCV Accuracy Scores:\\n [0.48033538 0.22054698 0.4483185  0.58703983 0.67637448]\\nMean CV Accuracy:  0.4825\\nStandard Deviation:  0.30764698041928257 \\n\\naugment_gpt3_multilabel\\nMean CV Accuracy:  0.6999\\n\\naugment_gpt3_fix\\nMean CV Accuracy:  0.6388\\n\\naugment_gpt4_multilabel_RespPerc.csv\\nMean CV Accuracy:  0.6848\\n\\naugment_gpt4_multilabel_RespPerc_fix.csv\\nMean CV Accuracy:  0.6365\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos validación cruzada y obtenemos las predicciones\n",
        "#predicciones = cross_val_predict(SVC_pipeline, texts, y, cv=5)\n",
        "predicciones = cross_val_predict(SVC_pipeline, texts, y, cv=KFold(n_splits=5,shuffle=True, random_state=1))\n",
        "\n",
        "# Calculamos el f1_weighted para cada columna de salida y el f1_weighted medio ponderado\n",
        "f1_scores = []\n",
        "for i, columna in enumerate(y.columns):\n",
        "    f1 = f1_score(y[columna], predicciones[:, i], average='weighted')\n",
        "    f1_scores.append(f1)\n",
        "    print(f\"f1_weighted para {columna}: {f1:.4f}\")\n",
        "\n",
        "f1_weighted_media = sum(f1_scores) / len(f1_scores)\n",
        "print(f\"f1_weighted medio: {f1_weighted_media:.4f}\")\n",
        "\n",
        "''' Without Augment\n",
        "f1_weighted para AgradPerc: 0.4663\n",
        "f1_weighted para ApertPerc: 0.5708\n",
        "f1_weighted para ExtravPerc: 0.5614\n",
        "f1_weighted para NeurPerc: 0.4894\n",
        "f1_weighted para RespPerc: 0.6840\n",
        "f1_weighted medio: 0.5544\n",
        "'''\n",
        "\n",
        "''' With Augment v1\n",
        "f1_weighted para AgradPerc: 0.4482\n",
        "f1_weighted para ApertPerc: 0.5786\n",
        "f1_weighted para ExtravPerc: 0.5739\n",
        "f1_weighted para NeurPerc: 0.6099\n",
        "f1_weighted para RespPerc: 0.8186\n",
        "f1_weighted medio: 0.6058\n",
        "'''\n",
        "''' With Augment v2\n",
        "f1_weighted para AgradPerc: 0.3741\n",
        "f1_weighted para ApertPerc: 0.6224\n",
        "f1_weighted para ExtravPerc: 0.7651\n",
        "f1_weighted para NeurPerc: 0.6175\n",
        "f1_weighted para RespPerc: 0.6558\n",
        "f1_weighted medio: 0.6070\n",
        "\n",
        "augment_gpt3_multilabel\n",
        "f1_weighted para AgradPerc: 0.6621\n",
        "f1_weighted para ApertPerc: 0.5862\n",
        "f1_weighted para ExtravPerc: 0.6473\n",
        "f1_weighted para NeurPerc: 0.6034\n",
        "f1_weighted para RespPerc: 0.8410\n",
        "f1_weighted medio: 0.6680\n",
        "\n",
        "augment_gpt3_fix\n",
        "f1_weighted para AgradPerc: 0.6315\n",
        "f1_weighted para ApertPerc: 0.5323\n",
        "f1_weighted para ExtravPerc: 0.5970\n",
        "f1_weighted para NeurPerc: 0.5387\n",
        "f1_weighted para RespPerc: 0.8024\n",
        "f1_weighted medio: 0.6204\n",
        "\n",
        "augment_gpt4_multilabel_RespPerc.csv\n",
        "f1_weighted para AgradPerc: 0.7094\n",
        "f1_weighted para ApertPerc: 0.6874\n",
        "f1_weighted para ExtravPerc: 0.7650\n",
        "f1_weighted para NeurPerc: 0.7086\n",
        "f1_weighted para RespPerc: 0.7718\n",
        "f1_weighted medio: 0.7284\n",
        "\n",
        "augment_gpt4_multilabel_RespPerc_fix.csv\n",
        "f1_weighted para AgradPerc: 0.6762\n",
        "f1_weighted para ApertPerc: 0.6563\n",
        "f1_weighted para ExtravPerc: 0.7218\n",
        "f1_weighted para NeurPerc: 0.6933\n",
        "f1_weighted para RespPerc: 0.7725\n",
        "f1_weighted medio: 0.7040\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI9Y_vBlc9GG",
        "outputId": "de8d1e1c-ec22-4540-8bfd-6a4c559df3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_weighted para AgradPerc: 0.7072\n",
            "f1_weighted para ApertPerc: 0.6492\n",
            "f1_weighted para ExtravPerc: 0.6987\n",
            "f1_weighted para NeurPerc: 0.6934\n",
            "f1_weighted para RespPerc: 0.7879\n",
            "f1_weighted medio: 0.7073\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' With Augment v2\\nf1_weighted para AgradPerc: 0.3741\\nf1_weighted para ApertPerc: 0.6224\\nf1_weighted para ExtravPerc: 0.7651\\nf1_weighted para NeurPerc: 0.6175\\nf1_weighted para RespPerc: 0.6558\\nf1_weighted medio: 0.6070\\n\\naugment_gpt3_multilabel\\nf1_weighted para AgradPerc: 0.6621\\nf1_weighted para ApertPerc: 0.5862\\nf1_weighted para ExtravPerc: 0.6473\\nf1_weighted para NeurPerc: 0.6034\\nf1_weighted para RespPerc: 0.8410\\nf1_weighted medio: 0.6680\\n\\naugment_gpt3_fix\\nf1_weighted para AgradPerc: 0.6315\\nf1_weighted para ApertPerc: 0.5323\\nf1_weighted para ExtravPerc: 0.5970\\nf1_weighted para NeurPerc: 0.5387\\nf1_weighted para RespPerc: 0.8024\\nf1_weighted medio: 0.6204\\n\\naugment_gpt4_multilabel_RespPerc.csv\\nf1_weighted para AgradPerc: 0.7094\\nf1_weighted para ApertPerc: 0.6874\\nf1_weighted para ExtravPerc: 0.7650\\nf1_weighted para NeurPerc: 0.7086\\nf1_weighted para RespPerc: 0.7718\\nf1_weighted medio: 0.7284\\n\\naugment_gpt4_multilabel_RespPerc_fix.csv\\nf1_weighted para AgradPerc: 0.6762\\nf1_weighted para ApertPerc: 0.6563\\nf1_weighted para ExtravPerc: 0.7218\\nf1_weighted para NeurPerc: 0.6933\\nf1_weighted para RespPerc: 0.7725\\nf1_weighted medio: 0.7040\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####DecissionTreeClassifier"
      ],
      "metadata": {
        "id": "visk4xuK3Q8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DecissionTreeClassifier\n",
        "\n",
        "DTC_pipeline = Pipeline([\n",
        "                ('tfidf', vect ),\n",
        "                ('clf', MultiOutputClassifier(DecisionTreeClassifier(\n",
        "                    criterion='gini',\n",
        "                    max_depth= 5,\n",
        "                    min_samples_leaf= 11,\n",
        "                    splitter='best',\n",
        "                    random_state=1), n_jobs=1)),\n",
        "            ])\n",
        "\n",
        "\n",
        "#scores = cross_val_score(DTC_pipeline, texts, y, cv=5, scoring='f1_weighted')\n",
        "scores = cross_val_score(DTC_pipeline, texts, y, cv=KFold(n_splits=5,shuffle=True, random_state=1), scoring='f1_weighted' )\n",
        "\n",
        "#print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "print(\"CV Accuracy Scores:\\n\", scores)\n",
        "print(\"Mean CV Accuracy: \", round(scores.mean(), 4))\n",
        "print(\"Standard Deviation: \", scores.std() * 2)\n",
        "\n",
        "''' Without Augment\n",
        "CV Accuracy Scores:\n",
        " [0.41465517 0.45264414 0.53197133 0.64081678 0.61868626]\n",
        "Mean CV Accuracy:  0.5318\n",
        "Standard Deviation:  0.17758932376221692\n",
        "'''\n",
        "''' With Augment v1\n",
        "CV Accuracy Scores:\n",
        " [0.54450099 0.53974068 0.5883676  0.86711205 0.65198172]\n",
        "Mean CV Accuracy:  0.6383\n",
        "Standard Deviation:  0.24256557918226068\n",
        "'''\n",
        "''' With Augment v2\n",
        "CV Accuracy Scores:\n",
        " [0.47272454 0.35883433 0.54863933 0.43092006 0.55499263]\n",
        "Mean CV Accuracy:  0.4732\n",
        "Standard Deviation:  0.14764403084225147\n",
        "\n",
        "augment_gpt3_multilabel\n",
        "Mean CV Accuracy:  0.6422\n",
        "\n",
        "augment_gpt3_fix\n",
        "Mean CV Accuracy:  0.583\n",
        "\n",
        "augment_gpt4_multilabel_RespPerc.csv\n",
        "Mean CV Accuracy:  0.5778\n",
        "\n",
        "augment_gpt4_multilabel_RespPerc_fix.csv\n",
        "Mean CV Accuracy:  0.5106\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCkh1sxEDztK",
        "outputId": "ec77f684-2c96-4b01-a3ce-38d0a28d398e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV Accuracy Scores:\n",
            " [0.4936805  0.5442077  0.63164201 0.5402968  0.45755964]\n",
            "Mean CV Accuracy:  0.5335\n",
            "Standard Deviation:  0.11711612564721742\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' With Augment v2\\nCV Accuracy Scores:\\n [0.47272454 0.35883433 0.54863933 0.43092006 0.55499263]\\nMean CV Accuracy:  0.4732\\nStandard Deviation:  0.14764403084225147\\n\\naugment_gpt3_multilabel\\nMean CV Accuracy:  0.6422\\n\\naugment_gpt3_fix\\nMean CV Accuracy:  0.583\\n\\naugment_gpt4_multilabel_RespPerc.csv\\nMean CV Accuracy:  0.5778\\n\\naugment_gpt4_multilabel_RespPerc_fix.csv\\nMean CV Accuracy:  0.5106\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos validación cruzada y obtenemos las predicciones\n",
        "#predicciones = cross_val_predict(DTC_pipeline, texts, y, cv=5)\n",
        "predicciones = cross_val_predict(DTC_pipeline, texts, y, cv=KFold(n_splits=5,shuffle=True, random_state=1))\n",
        "\n",
        "# Calculamos el f1_weighted para cada columna de salida y el f1_weighted medio ponderado\n",
        "f1_scores = []\n",
        "for i, columna in enumerate(y.columns):\n",
        "    f1 = f1_score(y[columna], predicciones[:, i], average='weighted')\n",
        "    f1_scores.append(f1)\n",
        "    print(f\"f1_weighted para {columna}: {f1:.4f}\")\n",
        "\n",
        "f1_weighted_media = sum(f1_scores) / len(f1_scores)\n",
        "print(f\"f1_weighted medio: {f1_weighted_media:.4f}\")\n",
        "\n",
        "''' Without Augment\n",
        "f1_weighted para AgradPerc: 0.5517\n",
        "f1_weighted para ApertPerc: 0.5688\n",
        "f1_weighted para ExtravPerc: 0.5453\n",
        "f1_weighted para NeurPerc: 0.5303\n",
        "f1_weighted para RespPerc: 0.6891\n",
        "f1_weighted medio: 0.5771\n",
        "'''\n",
        "''' With Augment v1\n",
        "f1_weighted para AgradPerc: 0.5587\n",
        "f1_weighted para ApertPerc: 0.5312\n",
        "f1_weighted para ExtravPerc: 0.6098\n",
        "f1_weighted para NeurPerc: 0.5832\n",
        "f1_weighted para RespPerc: 0.7274\n",
        "f1_weighted medio: 0.6020\n",
        "'''\n",
        "''' With Augment v2\n",
        "f1_weighted para AgradPerc: 0.3396\n",
        "f1_weighted para ApertPerc: 0.6454\n",
        "f1_weighted para ExtravPerc: 0.6785\n",
        "f1_weighted para NeurPerc: 0.6336\n",
        "f1_weighted para RespPerc: 0.5207\n",
        "f1_weighted medio: 0.5636\n",
        "\n",
        "augment_gpt3_multilabel\n",
        "f1_weighted para AgradPerc: 0.6388\n",
        "f1_weighted para ApertPerc: 0.5468\n",
        "f1_weighted para ExtravPerc: 0.6062\n",
        "f1_weighted para NeurPerc: 0.5686\n",
        "f1_weighted para RespPerc: 0.7581\n",
        "f1_weighted medio: 0.6237\n",
        "\n",
        "augment_gpt3_fix\n",
        "f1_weighted para AgradPerc: 0.6017\n",
        "f1_weighted para ApertPerc: 0.4533\n",
        "f1_weighted para ExtravPerc: 0.5513\n",
        "f1_weighted para NeurPerc: 0.5417\n",
        "f1_weighted para RespPerc: 0.7305\n",
        "f1_weighted medio: 0.5757\n",
        "\n",
        "augment_gpt4_multilabel_RespPerc.csv\n",
        "f1_weighted para AgradPerc: 0.5966\n",
        "f1_weighted para ApertPerc: 0.5957\n",
        "f1_weighted para ExtravPerc: 0.6740\n",
        "f1_weighted para NeurPerc: 0.6271\n",
        "f1_weighted para RespPerc: 0.6638\n",
        "f1_weighted medio: 0.6315\n",
        "\n",
        "augment_gpt4_multilabel_RespPerc_fix.csv\n",
        "f1_weighted para AgradPerc: 0.5990\n",
        "f1_weighted para ApertPerc: 0.5249\n",
        "f1_weighted para ExtravPerc: 0.6403\n",
        "f1_weighted para NeurPerc: 0.5904\n",
        "f1_weighted para RespPerc: 0.6455\n",
        "f1_weighted medio: 0.6000\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYcS97RzdKyP",
        "outputId": "25cb37ee-bb92-4f1b-9ebc-2753073c2b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_weighted para AgradPerc: 0.6059\n",
            "f1_weighted para ApertPerc: 0.5852\n",
            "f1_weighted para ExtravPerc: 0.6531\n",
            "f1_weighted para NeurPerc: 0.5682\n",
            "f1_weighted para RespPerc: 0.6696\n",
            "f1_weighted medio: 0.6164\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' With Augment v2\\nf1_weighted para AgradPerc: 0.3396\\nf1_weighted para ApertPerc: 0.6454\\nf1_weighted para ExtravPerc: 0.6785\\nf1_weighted para NeurPerc: 0.6336\\nf1_weighted para RespPerc: 0.5207\\nf1_weighted medio: 0.5636\\n\\naugment_gpt3_multilabel\\nf1_weighted para AgradPerc: 0.6388\\nf1_weighted para ApertPerc: 0.5468\\nf1_weighted para ExtravPerc: 0.6062\\nf1_weighted para NeurPerc: 0.5686\\nf1_weighted para RespPerc: 0.7581\\nf1_weighted medio: 0.6237\\n\\naugment_gpt3_fix\\nf1_weighted para AgradPerc: 0.6017\\nf1_weighted para ApertPerc: 0.4533\\nf1_weighted para ExtravPerc: 0.5513\\nf1_weighted para NeurPerc: 0.5417\\nf1_weighted para RespPerc: 0.7305\\nf1_weighted medio: 0.5757\\n\\naugment_gpt4_multilabel_RespPerc.csv\\nf1_weighted para AgradPerc: 0.5966\\nf1_weighted para ApertPerc: 0.5957\\nf1_weighted para ExtravPerc: 0.6740\\nf1_weighted para NeurPerc: 0.6271\\nf1_weighted para RespPerc: 0.6638\\nf1_weighted medio: 0.6315\\n\\naugment_gpt4_multilabel_RespPerc_fix.csv\\nf1_weighted para AgradPerc: 0.5990\\nf1_weighted para ApertPerc: 0.5249\\nf1_weighted para ExtravPerc: 0.6403\\nf1_weighted para NeurPerc: 0.5904\\nf1_weighted para RespPerc: 0.6455\\nf1_weighted medio: 0.6000\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####LogisticRegression"
      ],
      "metadata": {
        "id": "CCptSWgU3TiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CROSS VALIDATION\n",
        "LogReg_pipeline = Pipeline([\n",
        "                ('tfidf', vect),\n",
        "                ('clf', MultiOutputClassifier(LogisticRegression(solver='sag', max_iter=1000), n_jobs=1)),\n",
        "            ])\n",
        "\n",
        "\n",
        "#scores = cross_val_score(LogReg_pipeline, texts, y, cv=5, scoring='f1_weighted')\n",
        "scores = cross_val_score(LogReg_pipeline, texts, y, cv=KFold(n_splits=5,shuffle=True, random_state=1), scoring='f1_weighted' )\n",
        "\n",
        "#print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "print(\"CV Accuracy Scores:\\n\", scores)\n",
        "print(\"Mean CV Accuracy: \", round(scores.mean(), 4))\n",
        "print(\"Standard Deviation: \", scores.std() * 2)\n",
        "\n",
        "''' Without Augment\n",
        "CV Accuracy Scores:\n",
        " [0.42536765 0.47589809 0.64642564 0.54103129 0.63061472]\n",
        "Mean CV Accuracy:  0.5439\n",
        "Standard Deviation:  0.17137876330304774\n",
        "'''\n",
        "''' With Augment v1\n",
        "CV Accuracy Scores:\n",
        " [0.49535563 0.53616199 0.62553213 0.91813192 0.70175253]\n",
        "Mean CV Accuracy:  0.6554\n",
        "Standard Deviation:  0.2991997467608627\n",
        "'''\n",
        "''' With Augment v2\n",
        "CV Accuracy Scores:\n",
        " [0.50920073 0.42364637 0.56341684 0.64052527 0.71406389]\n",
        "Mean CV Accuracy:  0.5702\n",
        "Standard Deviation:  0.20176688324919498\n",
        "\n",
        "augment_gpt3_multilabel\n",
        "Mean CV Accuracy:  0.7091\n",
        "\n",
        "augment_gpt3_fix\n",
        "Mean CV Accuracy:  0.6507\n",
        "\n",
        "augment_gpt4_multilabel_RespPerc.csv\n",
        "Mean CV Accuracy:  0.6878\n",
        "\n",
        "augment_gpt4_multilabel_RespPerc_fix.csv\n",
        "Mean CV Accuracy:  0.6411\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OwdpZatWFdE",
        "outputId": "6433b59d-a984-44e0-efc5-b2c98a56b2b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV Accuracy Scores:\n",
            " [0.55677582 0.60808687 0.66937264 0.64946885 0.61444366]\n",
            "Mean CV Accuracy:  0.6196\n",
            "Standard Deviation:  0.07733292500806675\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' With Augment v2\\nCV Accuracy Scores:\\n [0.50920073 0.42364637 0.56341684 0.64052527 0.71406389]\\nMean CV Accuracy:  0.5702\\nStandard Deviation:  0.20176688324919498\\n\\naugment_gpt3_multilabel\\nMean CV Accuracy:  0.7091\\n\\naugment_gpt3_fix\\nMean CV Accuracy:  0.6507\\n\\naugment_gpt4_multilabel_RespPerc.csv\\nMean CV Accuracy:  0.6878\\n\\naugment_gpt4_multilabel_RespPerc_fix.csv\\nMean CV Accuracy:  0.6411\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos validación cruzada y obtenemos las predicciones\n",
        "predicciones = cross_val_predict(LogReg_pipeline, texts, y, cv=5)\n",
        "\n",
        "# Calculamos el f1_weighted para cada columna de salida y el f1_weighted medio ponderado\n",
        "f1_scores = []\n",
        "for i, columna in enumerate(y.columns):\n",
        "    f1 = f1_score(y[columna], predicciones[:, i], average='weighted')\n",
        "    f1_scores.append(f1)\n",
        "    print(f\"f1_weighted para {columna}: {f1:.4f}\")\n",
        "\n",
        "f1_weighted_media = sum(f1_scores) / len(f1_scores)\n",
        "print(f\"f1_weighted medio: {f1_weighted_media:.4f}\")\n",
        "\n",
        "''' Without Augment\n",
        "f1_weighted para AgradPerc: 0.4818\n",
        "f1_weighted para ApertPerc: 0.5752\n",
        "f1_weighted para ExtravPerc: 0.5728\n",
        "f1_weighted para NeurPerc: 0.4923\n",
        "f1_weighted para RespPerc: 0.7230\n",
        "f1_weighted medio: 0.5690\n",
        "'''\n",
        "''' With Augment v1\n",
        "\n",
        "'''\n",
        "''' With Augment v2\n",
        "f1_weighted para AgradPerc: 0.4557\n",
        "f1_weighted para ApertPerc: 0.6548\n",
        "f1_weighted para ExtravPerc: 0.7530\n",
        "f1_weighted para NeurPerc: 0.6639\n",
        "f1_weighted para RespPerc: 0.6531\n",
        "f1_weighted medio: 0.6361\n",
        "\n",
        "augment_gpt3_multilabel\n",
        "f1_weighted para AgradPerc: 0.5474\n",
        "f1_weighted para ApertPerc: 0.6037\n",
        "f1_weighted para ExtravPerc: 0.6183\n",
        "f1_weighted para NeurPerc: 0.6303\n",
        "f1_weighted para RespPerc: 0.7406\n",
        "f1_weighted medio: 0.6281\n",
        "\n",
        "augment_gpt3_fix\n",
        "f1_weighted para AgradPerc: 0.5327\n",
        "f1_weighted para ApertPerc: 0.5720\n",
        "f1_weighted para ExtravPerc: 0.5837\n",
        "f1_weighted para NeurPerc: 0.5177\n",
        "f1_weighted para RespPerc: 0.7101\n",
        "f1_weighted medio: 0.5833\n",
        "\n",
        "augment_gpt4_multilabel_RespPerc.csv\n",
        "f1_weighted para AgradPerc: 0.4272\n",
        "f1_weighted para ApertPerc: 0.6455\n",
        "f1_weighted para ExtravPerc: 0.7614\n",
        "f1_weighted para NeurPerc: 0.6518\n",
        "f1_weighted para RespPerc: 0.6429\n",
        "f1_weighted medio: 0.6258\n",
        "\n",
        "augment_gpt4_multilabel_RespPerc_fix.csv\n",
        "f1_weighted para AgradPerc: 0.5333\n",
        "f1_weighted para ApertPerc: 0.6565\n",
        "f1_weighted para ExtravPerc: 0.7232\n",
        "f1_weighted para NeurPerc: 0.7036\n",
        "f1_weighted para RespPerc: 0.6751\n",
        "f1_weighted medio: 0.6583\n",
        "\n",
        "augment_gpt4_multilabel_RespPerc_fix.csv\n",
        "f1_weighted para AgradPerc: 0.5333\n",
        "f1_weighted para ApertPerc: 0.6565\n",
        "f1_weighted para ExtravPerc: 0.7232\n",
        "f1_weighted para NeurPerc: 0.7036\n",
        "f1_weighted para RespPerc: 0.6751\n",
        "f1_weighted medio: 0.6583\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5LP4M-AdOW2",
        "outputId": "e7f024b3-9723-4866-edde-7e1577e2fd0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_weighted para AgradPerc: 0.5173\n",
            "f1_weighted para ApertPerc: 0.6767\n",
            "f1_weighted para ExtravPerc: 0.6892\n",
            "f1_weighted para NeurPerc: 0.6799\n",
            "f1_weighted para RespPerc: 0.6362\n",
            "f1_weighted medio: 0.6399\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' With Augment v2\\nf1_weighted para AgradPerc: 0.4557\\nf1_weighted para ApertPerc: 0.6548\\nf1_weighted para ExtravPerc: 0.7530\\nf1_weighted para NeurPerc: 0.6639\\nf1_weighted para RespPerc: 0.6531\\nf1_weighted medio: 0.6361\\n\\naugment_gpt3_multilabel\\nf1_weighted para AgradPerc: 0.5474\\nf1_weighted para ApertPerc: 0.6037\\nf1_weighted para ExtravPerc: 0.6183\\nf1_weighted para NeurPerc: 0.6303\\nf1_weighted para RespPerc: 0.7406\\nf1_weighted medio: 0.6281\\n\\naugment_gpt3_fix\\nf1_weighted para AgradPerc: 0.5327\\nf1_weighted para ApertPerc: 0.5720\\nf1_weighted para ExtravPerc: 0.5837\\nf1_weighted para NeurPerc: 0.5177\\nf1_weighted para RespPerc: 0.7101\\nf1_weighted medio: 0.5833\\n\\naugment_gpt4_multilabel_RespPerc.csv\\nf1_weighted para AgradPerc: 0.4272\\nf1_weighted para ApertPerc: 0.6455\\nf1_weighted para ExtravPerc: 0.7614\\nf1_weighted para NeurPerc: 0.6518\\nf1_weighted para RespPerc: 0.6429\\nf1_weighted medio: 0.6258\\n\\naugment_gpt4_multilabel_RespPerc_fix.csv\\nf1_weighted para AgradPerc: 0.5333\\nf1_weighted para ApertPerc: 0.6565\\nf1_weighted para ExtravPerc: 0.7232\\nf1_weighted para NeurPerc: 0.7036\\nf1_weighted para RespPerc: 0.6751\\nf1_weighted medio: 0.6583\\n\\naugment_gpt4_multilabel_RespPerc_fix.csv\\nf1_weighted para AgradPerc: 0.5333\\nf1_weighted para ApertPerc: 0.6565\\nf1_weighted para ExtravPerc: 0.7232\\nf1_weighted para NeurPerc: 0.7036\\nf1_weighted para RespPerc: 0.6751\\nf1_weighted medio: 0.6583\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}