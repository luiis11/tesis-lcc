{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luimont/tesis-lcc/blob/main/Notebooks/LIWC_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXyHuWt7CkOY"
      },
      "source": [
        "# **LIWC Classification**\n",
        "\n",
        "**Notebook de Pruebas con LIWC**\n",
        "\n",
        "En esta notebook se realizan pruebas con vectores de LIWC obtenidos desde los datos reales de estudio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mldrxUaIACI"
      },
      "source": [
        "### Representacion de BOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDgIOi4XCcza",
        "outputId": "ec4654f2-3202-4f00-a46e-6c89167ae558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# General Libraries\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os                # para manipulacion de directorios\n",
        "import shutil            # para eliminar carpetas no vacias\n",
        "#!pip install mglearn    # el comando 'import mglearn' no funcionaba\n",
        "\n",
        "# Preprocessing\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# CountVectorizer | TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# Cross Validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# GridSearch\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# LogisticRegression Classifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# SVM Classifier\n",
        "from sklearn import svm\n",
        "\n",
        "# KNN Clasificator\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
        "\n",
        "# Gaussian NaiveBayes Clasificator\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# RandomForest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# DecisionTree (Classifier and Regressor)\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Graphics library\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#path_colab  = \"https://drive.google.com/file/d/1ibZ-jIiQf5af18V6emfq6U3Dg6yq9Ij3/view\" #\"./90FeaturesLIWC.csv\",\n",
        "path_colab  = \"https://drive.google.com/file/d/1U-3dNmKGQ-MUrt7nHbyf_hbF6aZCP5LW/view\" #\"./datasets_full/ID-90FeatureLIWC_Labels.csv\",\n",
        "\n",
        "\n",
        "# With ONLY URL\n",
        "if path_colab.startswith('http'):\n",
        "  print(\"Ubication WEB\")\n",
        "  path_colab='https://drive.google.com/uc?id=' + path_colab.split('/')[-2]\n",
        "else: print(\"Ubication Local\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjYe2-qd6M_v",
        "outputId": "c8d80d1e-e2e0-4548-c5c3-abf49773d1d0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ubication WEB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lectura del DataFrame desde el CSV\n",
        "\n",
        "Selección de las columnas 7 hasta el final (corresponde a todas las feature o características de Liwc)\n",
        "\n",
        "[Visualizar archivo CSV para ver las columnas]"
      ],
      "metadata": {
        "id": "jCgKqavsVGho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_ = pd.read_csv(\n",
        "    #'ID-90FeatureLIWC_Labels.csv',\n",
        "    path_colab,\n",
        "    encoding = \"utf-8\",\n",
        "    header = 0,\n",
        "    # names = [\"ID\",\"NeuroPerc\", \"Autodescripción\"],\n",
        ")\n",
        "\n",
        "# Labels (All Personalities)\n",
        "#df_labels = df_.iloc[:,1:6]\n",
        "\n",
        "# Labels (only \"AGRADO\")\n",
        "#colum_title = [\"AgradPerc\", \"ApertPerc\", \"ExtravPerc\", \"NeurPerc\", \"RespPerc\"]\n",
        "#POS = 0\n",
        "\n",
        "#df_labels = list(df_[colum_title[POS]])\n",
        "#df_labels = list(df_[\"AgradPerc\"])\n",
        "## Labels (only \"AGRADO\")\n",
        "#df_labels = list(df_[\"AgradPerc\"])\n",
        "## Labels (only \"AGRADO\")\n",
        "#df_labels = list(df_[\"AgradPerc\"])\n",
        "## Labels (only \"AGRADO\")\n",
        "#df_labels = list(df_[\"AgradPerc\"])\n",
        "## Labels (only \"AGRADO\")\n",
        "#df_labels = list(df_[\"AgradPerc\"])\n",
        "\n",
        "\n",
        "# X_Train (corpus-matrix-liwc)\n",
        "df_features = df_.iloc[:,7:] # Select From column numer 7 to end\n",
        "#print(df2[0:3])\n",
        "#print(df2.to_numpy())\n",
        "\n",
        "\n",
        "#df2.index.to_numpy()\n",
        "#print(df2[0:3])\n",
        "# array(['a', 'b', 'c'], dtype=object)"
      ],
      "metadata": {
        "id": "quWE29-h6M9A"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seleccionar la personalidad editando el valor de la variable POS"
      ],
      "metadata": {
        "id": "hyeOb002U-Vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the Personality\n",
        "\n",
        "# 0: Agrado\n",
        "# 1: Apertura\n",
        "# 2: Extraversion\n",
        "# 3: Neuroticismo\n",
        "# 4: Responsabilidad\n",
        "\n",
        "POS = 4\n",
        "\n",
        "personality = [\"Agrado\", \"Apertura\", \"Extraversion\", \"Neuroticismo\", \"Responsabilidad\"]\n",
        "colum_title = [\"AgradPerc\", \"ApertPerc\", \"ExtravPerc\", \"NeurPerc\", \"RespPerc\"]\n",
        "\n",
        "\n",
        "# Selection from personality labels\n",
        "df_labels = list(df_[colum_title[POS]])\n",
        "\n",
        "print(f\"Personality Selected: {personality[POS]}\")\n",
        "#print(\"DataFrame\\n----------\\n\", df_labels)\n",
        "#print('DataFrame\\n----------\\n', df_features)\n",
        "#print('\\nDataFrame datatypes :\\n', df_features.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlOXfpZ5M6eB",
        "outputId": "5781c7b3-627a-41f5-e12f-be87057ba10a"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Personality Selected: Responsabilidad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Muestra de los primeros 2 elementos de vector_array y vector_label"
      ],
      "metadata": {
        "id": "8xsO3yTnU3f7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert pandas dataframe to numpy array\n",
        "vector_array = df_features.to_numpy()\n",
        "print('\\nNumpy Array\\n----------\\n', vector_array[0:2])\n",
        "print('\\nNumpy Array Datatype :', vector_array.dtype)\n",
        "\n",
        "\n",
        "#convert pandas dataframe to numpy array\n",
        "vector_label = df_labels#.to_numpy()\n",
        "print('\\nNumpy Array\\n----------\\n', vector_label[0:2])\n",
        "\n",
        "# Convert entire DataFrame string to float\n",
        "# df3 = df2.astype(float)\n",
        "# print(df2.dtypes)\n",
        "\n",
        "# df2['WC'].to_numpy()\n",
        "# print(df2[0:3])\n",
        "# array([1, 2, 3])\n",
        "\n",
        "#df_.as_matrix( columns=[df_[8:10]] )\n",
        "#Suffle the Data\n",
        "#df=df_.sample(frac=1)\n",
        "#\n",
        "#texts_unprocessed = list(df[\"Autodescripción\"])   #será el X_train o simplemente X es decir, los datos, en cross_val_score function\n",
        "#labels = list(df[colum_labels])               #será el y_train o simplemente y es decir, los labels, en cross_val_score function que usará para evaluar el clasificador\n",
        "#print(\"Textos:   \", texts_unprocessed[0:3])\n",
        "#print(\"Etiquetas:\", labels[0:3])"
      ],
      "metadata": {
        "id": "ivcmbOhX6M6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70e7c8ff-2603-42cd-9bb5-e8e0171ec754"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Numpy Array\n",
            "----------\n",
            " [[7.350e+02 3.196e+01 1.823e+01 9.524e+01 5.320e+01 1.946e+01 1.211e+01\n",
            "  7.890e+00 2.700e-01 1.400e-01 4.080e+00 8.200e-01 7.350e+00 6.260e+00\n",
            "  1.578e+01 1.630e+00 2.310e+00 1.347e+01 0.000e+00 8.980e+00 1.075e+01\n",
            "  7.760e+00 1.630e+00 3.810e+00 1.360e+00 2.700e-01 4.760e+00 0.000e+00\n",
            "  4.100e-01 2.720e+00 4.100e-01 1.220e+00 1.400e-01 0.000e+00 0.000e+00\n",
            "  0.000e+00 1.102e+01 2.860e+00 1.500e+00 2.310e+00 7.890e+00 5.170e+00\n",
            "  2.860e+00 0.000e+00 2.180e+00 2.700e-01 3.020e+01 4.220e+00 2.450e+00\n",
            "  1.500e+00 4.220e+00 3.130e+00 5.400e-01 8.710e+00 1.900e+00 3.670e+00\n",
            "  1.500e+00 2.700e-01 6.800e-01 2.310e+00 5.400e-01 8.200e-01 2.700e-01\n",
            "  6.800e-01 1.497e+01 3.540e+00 4.900e+00 6.800e+00 2.310e+00 2.590e+00\n",
            "  3.270e+00 1.900e+00 1.400e-01 0.000e+00 0.000e+00 5.400e-01 0.000e+00\n",
            "  0.000e+00 4.900e+00 2.990e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 2.700e-01 0.000e+00 1.630e+00 0.000e+00]\n",
            " [1.237e+03 2.689e+01 1.754e+01 9.159e+01 5.190e+01 1.698e+01 1.108e+01\n",
            "  6.550e+00 1.130e+00 1.600e-01 4.120e+00 1.290e+00 5.900e+00 7.920e+00\n",
            "  1.471e+01 1.050e+00 8.900e-01 1.310e+01 0.000e+00 6.470e+00 1.269e+01\n",
            "  6.950e+00 2.100e+00 2.990e+00 2.100e+00 0.000e+00 4.040e+00 0.000e+00\n",
            "  4.900e-01 2.990e+00 7.300e-01 1.290e+00 8.000e-02 0.000e+00 1.600e-01\n",
            "  0.000e+00 1.075e+01 1.050e+00 6.500e-01 1.290e+00 6.390e+00 3.960e+00\n",
            "  1.460e+00 4.900e-01 4.000e-01 2.400e-01 2.708e+01 4.120e+00 2.830e+00\n",
            "  1.050e+00 4.450e+00 2.510e+00 4.000e-01 7.440e+00 2.910e+00 3.070e+00\n",
            "  8.900e-01 1.130e+00 5.700e-01 2.510e+00 8.900e-01 4.000e-01 1.600e-01\n",
            "  1.050e+00 1.447e+01 3.230e+00 5.250e+00 6.950e+00 2.910e+00 1.620e+00\n",
            "  2.830e+00 1.460e+00 2.400e-01 0.000e+00 8.000e-02 4.000e-01 0.000e+00\n",
            "  0.000e+00 5.250e+00 3.960e+00 0.000e+00 0.000e+00 0.000e+00 7.300e-01\n",
            "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.600e-01 4.000e-01]]\n",
            "\n",
            "Numpy Array Datatype : float64\n",
            "\n",
            "Numpy Array\n",
            "----------\n",
            " [0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "T51OMtCjMUCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the combinations\n",
        "\n",
        "- With GridSearchCV, we can test the different combinations for parameters for Classifiers"
      ],
      "metadata": {
        "id": "BUuEf4wFOu_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifiers\n",
        "\n",
        "#SVM\n",
        "svc = svm.SVC()\n",
        "parameters_svc = [\n",
        "    {'kernel': ['linear'], 'C':[ 1, 100, 1000], 'gamma': [0.001, 0.01, 0.1]},\n",
        "    {'kernel': ['rbf', 'poly', 'sigmoid'], 'gamma':[1e-3, 1e-4,'scale','auto'], 'C':[1, 100, 1000]}\n",
        "    #{'kernel': ['linear'], 'C':[ 10, 100, 1000, 100000], 'gamma': [0.001, 0.01, 0.1, 1 ]},\n",
        "    #{'kernel': ['rbf', 'poly', 'sigmoid'], 'gamma':[1e-3, 1e-4,'scale','auto'], 'C':[1, 10, 100, 1000, 100000]}\n",
        "]\n",
        "\n",
        "#LogisticRegression\n",
        "lr = LogisticRegression(solver='liblinear', random_state=2, max_iter=50000)\n",
        "parameters_lr = [{'solver':['sag', 'newton-cg',  'saga', 'liblinear']}]\n",
        "\n",
        "#KNN\n",
        "knn = Pipeline([('mms', MaxAbsScaler()), ('knn', KNeighborsClassifier())])\n",
        "parameters_knn = [{'knn__n_neighbors': [1, 3, 5, 7, 8, 9, 10], 'knn__weights': ['uniform', 'distance'], 'knn__leaf_size': [15, 20]}]\n",
        "\n",
        "#NaiveBayes Gaussian\n",
        "gnb = GaussianNB()\n",
        "parameters_gnb = [{'var_smoothing': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]}]\n",
        "\n",
        "#NaiveBayes Multinomial\n",
        "gnm = MultinomialNB()\n",
        "parameters_gnm = [{'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], 'fit_prior' : [True, False] }]\n",
        "\n",
        "#RandomForest\n",
        "rf = RandomForestClassifier() #Initialize with whatever parameters you want to\n",
        "parameters_rf = [{'n_estimators': [5, 10, 15, 20], 'max_depth': [2, 5, 7, 9]}]\n",
        "\n",
        "#DecisionTreeClassifier\n",
        "dtc = DecisionTreeClassifier()\n",
        "parameters_dtc = [{\n",
        "    'splitter': ['best', 'random'], 'criterion': [\"gini\", \"entropy\"], \"max_depth\": [*range(1, 10)],\n",
        "    'min_samples_leaf': [*range(1, 50, 5)],#' min_impurity_decrease': [*np.linspace(0, 0.5, 20)]\n",
        "    #'max_features':[ None, 'auto','sqrt','log2'],   #Added\n",
        "    #'min_impurity_decrease': [None, 0.5]            #Added\n",
        "}]\n",
        "\n",
        "# #DecisionTreeRegressor\n",
        "# dtr = DecisionTreeRegressor()\n",
        "# parameters_dtr =[{\n",
        "#     \"criterion\": [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
        "#     \"splitter\":[\"best\",\"random\"], \"max_depth\" : [1,3,5,7,9,11,12], \"max_features\":[\"auto\",\"log2\",\"sqrt\",None], \"max_leaf_nodes\":[None,10,20,30,40,50,60,70,80,90],\n",
        "#     \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10], \"min_weight_fraction_leaf\":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "# }]\n",
        "\n",
        "# Group the Classifier with the corresponding params\n",
        "\n",
        "classifier_and_params = [\n",
        "  {'cslf':dtc , 'params':parameters_dtc, 'name':'dtc'},\n",
        "  {'cslf':rf , 'params':parameters_rf, 'name':'rf'},\n",
        "  {'cslf':knn , 'params':parameters_knn, 'name':'knn'},\n",
        "  {'cslf':svc , 'params':parameters_svc, 'name':'svc'},\n",
        "  {'cslf':gnb , 'params':parameters_gnb, 'name':'gnb'},\n",
        "  {'cslf':gnm , 'params':parameters_gnm, 'name':'gnm'},\n",
        "  {'cslf':lr , 'params':parameters_lr, 'name':'lr'}\n",
        "]\n",
        "\n",
        "print(f\"Total of Classifiers to test on GridSearch: {len(classifier_and_params)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3sj1t0A4LS9",
        "outputId": "ef1cae50-9170-4744-a733-f8ad03a3be07"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total of Classifiers to test on GridSearch: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#### GridSearch ####\n",
        "# Para NB (NaiveBayes) se necesita tener X_traing.toarray(), ya que es este el tipo de valor que espera\n",
        "\n",
        "def gridSearchProcess(classifier, params, name):\n",
        "  clf = GridSearchCV(\n",
        "      estimator=classifier,               # Pass the model instance for which you want to check the hyperparameters.\n",
        "      param_grid=params,                  # the dictionary object that holds the hyperparameters you want to try\n",
        "      scoring='f1_weighted',                 # evaluation metric that you want to use, you can simply pass a valid string/ object of evaluation metric\n",
        "      cv=KFold(n_splits=5, shuffle=True, random_state=1), # number of cross-validation you have to try for each selected set of hyperparameters\n",
        "      #refit=True,                          # Refit an estimator using the best found parameters on the whole dataset (default=True).\n",
        "      #n_jobs=-1,                         # number of processes you wish to run in parallel for this task if it -1 it will use all available processors.\n",
        "      #verbose=1,                         # you can set it to 1 to get the detailed print out while you fit the data to GridSearchCV\n",
        "  )\n",
        "  clf.fit(vector_array, vector_label)\n",
        "\n",
        "  # find best model score\n",
        "  best_params       = clf.best_params_\n",
        "  best_model_score  = clf.score(vector_array, vector_label)\n",
        "\n",
        "  print(f'\\n******** {name} Results ********')\n",
        "  #print(f'best_model_score: {round(best_model_score, 4)}')\n",
        "  print(f'best_score:       {round(clf.best_score_, 4)}')\n",
        "  print(f'scorer:           {clf.scoring}')\n",
        "  #print(f'best_estimator:{clf.best_estimator_}')\n",
        "  #print(f'best_index:       {clf.best_index_}')\n",
        "  #print(f'X_traing:         {len(X_train.toarray())}')\n",
        "  #print(f'n_splits:         {clf.n_splits_}')\n",
        "  print(f'best_params:      {clf.best_params_}')\n",
        "\n",
        "print(f\"Selected Tokenized Representation: LIWC\")\n",
        "print(f\"Selected Class Personality: {personality[POS]}\")\n",
        "\n",
        "for pair in classifier_and_params:\n",
        "    gridSearchProcess(classifier=pair['cslf'], params=pair['params'], name=pair['name'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSHgyZiR6JOf",
        "outputId": "e1da2694-ed11-4d89-ff4b-9013d5780d50"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Tokenized Representation: LIWC\n",
            "Selected Class Personality: Responsabilidad\n",
            "\n",
            "******** dtc Results ********\n",
            "best_score:       0.7211\n",
            "scorer:           f1_weighted\n",
            "best_params:      {'criterion': 'entropy', 'max_depth': 6, 'min_samples_leaf': 6, 'splitter': 'random'}\n",
            "\n",
            "******** rf Results ********\n",
            "best_score:       0.7123\n",
            "scorer:           f1_weighted\n",
            "best_params:      {'max_depth': 7, 'n_estimators': 5}\n",
            "\n",
            "******** knn Results ********\n",
            "best_score:       0.6901\n",
            "scorer:           f1_weighted\n",
            "best_params:      {'knn__leaf_size': 15, 'knn__n_neighbors': 7, 'knn__weights': 'uniform'}\n",
            "\n",
            "******** svc Results ********\n",
            "best_score:       0.7033\n",
            "scorer:           f1_weighted\n",
            "best_params:      {'C': 1000, 'gamma': 'scale', 'kernel': 'poly'}\n",
            "\n",
            "******** gnb Results ********\n",
            "best_score:       0.7265\n",
            "scorer:           f1_weighted\n",
            "best_params:      {'var_smoothing': 0.01}\n",
            "\n",
            "******** gnm Results ********\n",
            "best_score:       0.6961\n",
            "scorer:           f1_weighted\n",
            "best_params:      {'alpha': 0.1, 'fit_prior': True}\n",
            "\n",
            "******** lr Results ********\n",
            "best_score:       0.6979\n",
            "scorer:           f1_weighted\n",
            "best_params:      {'solver': 'sag'}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_Zu0HI0GMOVD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}